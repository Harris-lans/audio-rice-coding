{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "## Overview\n",
    "\n",
    "This python notebook implements the solution for a lossless compression and decompression algorithm using the `Rice Coding` method. This notebook only implements the solution and discusses the step-by-step implementation process. The theoretical aspects of these techniques will be further elaborated in the report submitted alongside this notebook.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### Install Dependencies\n",
    "\n",
    "We'll begin by installing the libraries required for building the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wave\n",
      "  Downloading Wave-0.0.2.zip (38 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.0.3)\n",
      "Collecting bitarray\n",
      "  Downloading bitarray-2.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
      "\u001b[K     |████████████████████████████████| 277 kB 67.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.45.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.18.4)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Building wheels for collected packages: wave\n",
      "  Building wheel for wave (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wave: filename=Wave-0.0.2-py3-none-any.whl size=1245 sha256=eabf2b77020dec3a0f532381793879b100a4efc3183aeb9f828c7d734bff8df9\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/25/e8/fe/458c7dac00c6abedad6380b9d0ef1a5cbc7c21807df1d30915\n",
      "Successfully built wave\n",
      "Installing collected packages: wave, bitarray\n",
      "Successfully installed bitarray-2.8.1 wave-0.0.2\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wave pandas bitarray tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following that we'll also create the output folder if it does not exist so that the application can save output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_files_folder = './Exercise_2_Output'\n",
    "\n",
    "if not os.path.exists(output_files_folder):\n",
    "    os.mkdir(output_files_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application\n",
    "\n",
    "#### Utility Functions\n",
    "\n",
    "We'll begin by creating some useful functions for working with Rice encoding and decoding of basic non-negative whole numbers. These functions include `rice_encode()` and `rice_decode()`, which are the heart of our compression technique. They rely on smaller functions like `unary_encode()`, `binary_encode()`, `unary_decode()`, and `binary_decode()` to do their jobs effectively.\n",
    "\n",
    "In addition to the main functions, we'll create four additional functions. One is called `read_file_as_byte_array()`, which allows us to read the content of a file and see it as a sequence of bytes. Another one is `compare_compressed_file_sizes()`, which helps us understand how effective our compression is. The last two are `calculate_file_hash()` and `compare_files()`, which help us confirm if the decoding process is functioning properly. These extra functions make our program more flexible and enable us to assess its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "\n",
    "def unary_encode(n: int) -> str:\n",
    "    \"\"\"\n",
    "    Encodes a non-negative integer using unary encoding.\n",
    "\n",
    "    Parameters:\n",
    "    n (int): The non-negative integer to be encoded.\n",
    "\n",
    "    Returns:\n",
    "    str: The unary encoded string representation of the integer.\n",
    "    \"\"\"\n",
    "    assert n >= 0, \"Input value must be non-negative.\"\n",
    "    \n",
    "    return '1' * n + '0'\n",
    "\n",
    "def binary_encode(n: int, k: int) -> str:\n",
    "    \"\"\"\n",
    "    Encodes an integer in binary format with a specified minimum width.\n",
    "\n",
    "    Parameters:\n",
    "    n (int): The integer to be encoded.\n",
    "    k (int): The minimum width of the binary representation.\n",
    "\n",
    "    Returns:\n",
    "    str: The binary encoded string representation of the integer.\n",
    "    \"\"\"\n",
    "    assert n >= 0, \"Input value must be non-negative.\"\n",
    "    assert k > 0, \"Minimum width 'k' must be greater than 0.\"\n",
    "    \n",
    "    return format(n, '0{}b'.format(k))\n",
    "\n",
    "def unary_decode(code: str) -> int:\n",
    "    \"\"\"\n",
    "    Decodes a unary encoded string to a non-negative integer.\n",
    "\n",
    "    Parameters:\n",
    "    code (str): The unary encoded string to be decoded.\n",
    "\n",
    "    Returns:\n",
    "    int: The decoded non-negative integer.\n",
    "    \"\"\"\n",
    "    assert all(char == '1' or char == '0' for char in code), \"Input code must consist of '0's and '1's only.\"\n",
    "    return code.count('1')\n",
    "\n",
    "def binary_decode(code: str) -> int:\n",
    "    \"\"\"\n",
    "    Decodes a binary encoded string to an integer.\n",
    "\n",
    "    Parameters:\n",
    "    code (str): The binary encoded string to be decoded.\n",
    "\n",
    "    Returns:\n",
    "    int: The decoded integer.\n",
    "    \"\"\"\n",
    "    assert all(char == '0' or char == '1' for char in code), \"Input code must consist of '0's and '1's only.\"\n",
    "    return int(code, 2)\n",
    "\n",
    "def rice_encode(value:int, k: int) -> str:\n",
    "    \"\"\"\n",
    "    Encodes an integer using Rice coding with a specified parameter.\n",
    "\n",
    "    Parameters:\n",
    "    value (int): The non-negative integer to be encoded.\n",
    "    k (int): The parameter value used in Rice coding.\n",
    "\n",
    "    Returns:\n",
    "    str: The Rice encoded string representation of the integer.\n",
    "    \"\"\"\n",
    "    assert value >= 0, \"Input value must be non-negative.\"\n",
    "    assert k > 0, \"Parameter 'k' must be greater than 0.\"\n",
    "    \n",
    "    modulus = 2**k\n",
    "    \n",
    "    quotient = value // modulus\n",
    "    remainder = value % modulus\n",
    "\n",
    "    quotient_code = unary_encode(quotient)\n",
    "    remainder_code = binary_encode(remainder, k)\n",
    "    rice_code = quotient_code + remainder_code\n",
    "\n",
    "    return rice_code\n",
    "\n",
    "def rice_decode(value: str, k: int) -> int:\n",
    "    \"\"\"\n",
    "    Decodes a Rice encoded string to an integer using a specified parameter.\n",
    "\n",
    "    Parameters:\n",
    "    value (str): The Rice encoded string to be decoded.\n",
    "    k (int): The parameter value used in Rice coding.\n",
    "\n",
    "    Returns:\n",
    "    int: The decoded integer.\n",
    "    \"\"\"\n",
    "    assert all(char == '0' or char == '1' for char in value), \"Input code must consist of '0's and '1's only.\"\n",
    "    assert k > 0, \"Parameter 'k' must be greater than 0.\"\n",
    "\n",
    "    modulus = 2 ** k\n",
    "\n",
    "    first_0_index = len(value) - 1\n",
    "    for index, char in enumerate(value):\n",
    "        if char == '0':\n",
    "            first_0_index = index\n",
    "            break\n",
    "\n",
    "    quotient_code = value[:first_0_index]\n",
    "    remainder_code = value[first_0_index:]\n",
    "\n",
    "    quotient = unary_decode(quotient_code)\n",
    "    remainder = binary_decode(remainder_code)\n",
    "    number = quotient * modulus + remainder\n",
    "\n",
    "    return number\n",
    "\n",
    "def read_file_as_byte_array(file_path: str):\n",
    "    \"\"\"\n",
    "    Reads a file as a byte array.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the file to be read.\n",
    "\n",
    "    Returns:\n",
    "    bytes: The contents of the file as a byte array.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        byte_array = file.read()\n",
    "    return byte_array\n",
    "\n",
    "def calculate_file_hash(file_path):\n",
    "    \"\"\"\n",
    "    Calculate the SHA-256 hash of a file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "    str: The SHA-256 hash in hexadecimal format.\n",
    "    \"\"\"\n",
    "    # Technique adpoted from -> https://www.geeksforgeeks.org/compare-two-files-using-hashing-in-python/\n",
    "    sha256_hash = hashlib.sha256()\n",
    "    \n",
    "    with open(file_path, \"rb\") as f:\n",
    "        # Read the file in chunks and update the hash\n",
    "        for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
    "            sha256_hash.update(byte_block)\n",
    "            \n",
    "    return sha256_hash.hexdigest()\n",
    "\n",
    "def compare_files(file_path_1, file_path_2):\n",
    "    \"\"\"\n",
    "    Compare two files by calculating their SHA-256 hashes.\n",
    "\n",
    "    Parameters:\n",
    "    file_path_1 (str): The path to the first file.\n",
    "    file_path_2 (str): The path to the second file.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the files have the same hash, False otherwise.\n",
    "    \"\"\"\n",
    "    hash_1 = calculate_file_hash(file_path_1)\n",
    "    hash_2 = calculate_file_hash(file_path_2)\n",
    "    \n",
    "    if hash_1 == hash_2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Functions\n",
    "\n",
    "Now that we have our encoding utility ready, we can move ahead and create functions to encode and decode files using the Rice Coding algorithm. Let's break down the steps each of these functions takes:\n",
    "\n",
    "##### Steps in the `rice_encode_audio_file()` Function\n",
    "1. The function begins by loading the file from the provided input path as an array of bytes.\n",
    "2. It then converts each byte into a string of Rice codes, resulting in a list of these code strings.\n",
    "3. These individual strings are joined together into a single big string.\n",
    "4. The combined string is split into smaller strings of 8 characters each, where each represents a byte. If the last string isn't 8 characters long, it's padded with zeros, and the count of those zeros is noted.\n",
    "5. The first byte in the final byte array holds the count of padded zeros.\n",
    "6. The 8-character strings are transformed into bytes and added to the final byte array.\n",
    "7. The complete byte array is saved to a given path as binary data.\n",
    "\n",
    "##### Steps in the `rice_decode_audio_file()` Function\n",
    "1. The function starts by loading the encoded file from the provided input path as an array of bytes.\n",
    "2. It turns each byte into a binary string, giving us a list of binary strings where each one represents the bits in a byte.\n",
    "3. These binary strings are combined into a single big string.\n",
    "4. The first 8 characters of this string are turned into a byte, helping us figure out the number of padding zeros added to the last byte.\n",
    "5. Reading through the string from start to end (ignoring the padding zeros), the function reconstructs the original byte value by identifying quotient and remainder values during the process.\n",
    "6. The reconstructed bytes are then written to the provided output path, creating a new WAV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rice_encode_audio_file(input_audio_file_path: str, output_audio_file_path: str, k: int):\n",
    "    # Load the audio file\n",
    "    audio_buffer = read_file_as_byte_array(input_audio_file_path)\n",
    "\n",
    "    # Encoding bytes\n",
    "    encoded_bit_strings = [ rice_encode(byte, k) for byte in audio_buffer ]\n",
    "    # Separate bits into groups of 8 for bytes\n",
    "    encoded_bit_string = \"\".join(encoded_bit_strings)\n",
    "    encoded_byte_bit_strings = [ encoded_bit_string[i : i+8] for i in range(0, len(encoded_bit_string), 8) ]\n",
    "    last_bit_string_padding_size = 8 - len(encoded_byte_bit_strings[-1])\n",
    "    \n",
    "    # Convert the binary string to bytes\n",
    "    i, encoded_audio_buffer = 0, bytearray()\n",
    "    # Adding the number of 0s added for padding to the beginning of the last encoded bit string\n",
    "    encoded_audio_buffer.append(last_bit_string_padding_size)\n",
    "    # Converting bits to bytes\n",
    "    for bit_string in encoded_byte_bit_strings:\n",
    "        byte = int(bit_string, 2)\n",
    "        encoded_audio_buffer.append(byte)\n",
    "\n",
    "    # Writing encoded audio samples to output file\n",
    "    with open(output_audio_file_path, 'wb+') as output_file:\n",
    "        output_file.write(encoded_audio_buffer)\n",
    "\n",
    "def rice_decode_audio_file(input_audio_file_path: str, output_audio_file_path: str, k: int):\n",
    "    # Load the encoded file\n",
    "    encoded_buffer = read_file_as_byte_array(input_audio_file_path)\n",
    "    # Extracting the first byte that contains the number of padding zeroes in the last \n",
    "    padding_size = encoded_buffer[0]\n",
    "\n",
    "    # Converting byte array into bit strings\n",
    "    encoded_bit_strings = [ binary_encode(byte, 8) for byte in encoded_buffer[1:] ]\n",
    "    # Removing any zeroes used as padding in the last byte\n",
    "    encoded_bit_strings[-1] = encoded_bit_strings[-1][padding_size:]\n",
    "    encoded_bit_string = ''.join(encoded_bit_strings)\n",
    "\n",
    "    i, decoded_buffer = 0, bytearray()\n",
    "    encoded_byte_start = 0\n",
    "    \n",
    "    while i < len(encoded_bit_string):\n",
    "        if encoded_bit_string[i] == '0':\n",
    "            encoded_byte_end = i + k + 1\n",
    "            decoded_byte = rice_decode(encoded_bit_string[encoded_byte_start : encoded_byte_end], k)\n",
    "            decoded_buffer.append(decoded_byte)\n",
    "            \n",
    "            i = encoded_byte_end\n",
    "            encoded_byte_start = i\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    # Writing encoded audio samples to output file\n",
    "    with open(output_audio_file_path, 'wb+') as output_file:\n",
    "        output_file.write(decoded_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing\n",
    "\n",
    "Now that our primary functions for encoding and decoding files with rice coding are in place, let's move forward and put them to the test. Our testing approach involves rice encoding the `./files/Sound1.wav` file using a `k` value of `2`. Subsequently, we'll perform a decoding operation on the encoded file and make a hash comparison with the original file to verify the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoding and decoding functions work!\n"
     ]
    }
   ],
   "source": [
    "# Encoding \n",
    "rice_encode_audio_file('./Exercise_2_Files/Sound1.wav', './Exercise_2_Output/Sound1_Enc_K_2.ex2', k = 2)\n",
    "\n",
    "# Decoding\n",
    "rice_decode_audio_file('./Exercise_2_Output/Sound1_Enc_K_2.ex2', './Exercise_2_Output/Sound1_Enc_Dec_K_2.wav', k = 2)\n",
    "\n",
    "# Comparing original file with the decoded file\n",
    "if compare_files('./Exercise_2_Files/Sound1.wav', './Exercise_2_Output/Sound1_Enc_Dec_K_2.wav'):\n",
    "    print('The encoding and decoding functions work!')\n",
    "else:\n",
    "    print('Something is wrong with the encoding and decoding functions!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output of the above cell, we can see the encoding and decoding functions work as expected.\n",
    "\n",
    "#### Compression Result\n",
    "\n",
    "With the working encoding and decoding functions working, we can construct the table requested in the task sheet to compare the compression effect of the different k values on the files. \n",
    "\n",
    "To do that we will encode the `./files/Sound1.wav` and `./files/Sound2.wav` files using both `k` values of `2` and `4` and compare file sizes to create the table using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>k</th>\n",
       "      <th>original_size</th>\n",
       "      <th>compressed_size</th>\n",
       "      <th>compression_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sound1.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>1002088</td>\n",
       "      <td>4115719</td>\n",
       "      <td>410.714328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sound1.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>1002088</td>\n",
       "      <td>1516266</td>\n",
       "      <td>151.310663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sound2.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>1008044</td>\n",
       "      <td>4348596</td>\n",
       "      <td>431.389503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sound2.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>1008044</td>\n",
       "      <td>1575348</td>\n",
       "      <td>156.277702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name  k  original_size  compressed_size  compression_percentage\n",
       "0  Sound1.wav  2        1002088          4115719              410.714328\n",
       "1  Sound1.wav  4        1002088          1516266              151.310663\n",
       "2  Sound2.wav  2        1008044          4348596              431.389503\n",
       "3  Sound2.wav  4        1008044          1575348              156.277702"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "audio_file_encoding_configs = [\n",
    "    {\n",
    "        'file_name': 'Sound1.wav',\n",
    "        'input_file_path': './Exercise_2_Files/Sound1.wav',\n",
    "        'output_file_path': './Exercise_2_Output/Sound1_Enc_K_2.ex2',\n",
    "        'k': 2\n",
    "    },\n",
    "    {\n",
    "        'file_name': 'Sound1.wav',\n",
    "        'input_file_path': './Exercise_2_Files/Sound1.wav',\n",
    "        'output_file_path': './Exercise_2_Output/Sound1_Enc_K_4.ex2',\n",
    "        'k': 4\n",
    "    },\n",
    "    {\n",
    "        'file_name': 'Sound2.wav',\n",
    "        'input_file_path': './Exercise_2_Files/Sound2.wav',\n",
    "        'output_file_path': './Exercise_2_Output/Sound2_Enc_K_2.ex2',\n",
    "        'k': 2\n",
    "    },\n",
    "    {\n",
    "        'file_name': 'Sound2.wav',\n",
    "        'input_file_path': './Exercise_2_Files/Sound2.wav',\n",
    "        'output_file_path': './Exercise_2_Output/Sound2_Enc_K_4.ex2',\n",
    "        'k': 4\n",
    "    }\n",
    "]\n",
    "\n",
    "file_size_dataframe = pd.DataFrame()\n",
    "\n",
    "for config in audio_file_encoding_configs:\n",
    "    file_name = config['file_name']\n",
    "    input_file_path = config['input_file_path']\n",
    "    output_file_path = config['output_file_path']\n",
    "    k = config['k']\n",
    "    \n",
    "    rice_encode_audio_file(input_file_path, output_file_path, k)\n",
    "    \n",
    "    original_size, compressed_size = os.path.getsize(config['input_file_path']), os.path.getsize(config['output_file_path'])\n",
    "    compression_percentage = (compressed_size / original_size) * 100\n",
    "    \n",
    "    new_row = {\n",
    "        'file_name': file_name, \n",
    "        'k': k,\n",
    "        'original_size': original_size, \n",
    "        'compressed_size': compressed_size,\n",
    "        'compression_percentage': compression_percentage\n",
    "    }\n",
    "    file_size_dataframe = pd.concat([file_size_dataframe, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "file_size_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Deveolopment\n",
    "\n",
    "For the further development we will be building a more effective compression solution the Lempel–Ziv–Storer–Szymanski(LZSS) algorithm. The algorithm implementation is adopted from this [blog](https://tim.cogan.dev/lzss/) on the LZSS algorithm by Tim Cogan.\n",
    "\n",
    "#### Utility Functions\n",
    "\n",
    "Similar to implementation of the rice coding algorithm, we will begin by implementing some useful utility functions that will help us encode audio files using the LZSS algorithm. These functions include `generate_repeated_sequence()` and `find_longest_match()`, where `generate_repeated_sequence()` is used for generating a sequence of bytes of a specified length using a pattern of bytes and `find_longest_match()` is used to find the longest match for a sequence of bytes within the provided window.\n",
    "\n",
    "The `find_longest_match()` is less trivial is implemented using the below steps:\n",
    "1. The function starts by defining the end index for the largest match candidate.\n",
    "2. Then the function defines the start index for pattern searching among the already encoded bytes before the `current_position`. The start_index depends on the provided `window_size`.\n",
    "3. The function then iterates through the possible match candidates, with each iteration reducing the length of the match candidate by 1. These match candidates are compared to the existing byte sequences(the bytes perceeding `current_position`). If a match candidate is found to be equal to an existing byte sequence the function returns the offset for the index of the begininning of that byte sequence from the `current_position` and the length of the repeating sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "from bitarray import bitarray\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def generate_repeated_sequence(x: bytes, num_bytes: int) -> bytes:\n",
    "    \"\"\"\n",
    "    Generate a sequence by repeating the given bytes and appending a portion of the bytes.\n",
    "\n",
    "    Examples:\n",
    "        generate_repeated_sequence(b\"1234567\", 5) -> b\"12345\"\n",
    "        generate_repeated_sequence(b\"123\", 5) -> b\"12312\"\n",
    "\n",
    "    Args:\n",
    "        x (bytes): The bytes to repeat and append.\n",
    "        num_bytes (int): The desired length of the generated sequence.\n",
    "\n",
    "    Returns:\n",
    "        bytes: The generated sequence of bytes.\n",
    "    \"\"\"\n",
    "    repetitions = num_bytes // len(x)\n",
    "    remainder = num_bytes % len(x)\n",
    "    \n",
    "    return x * repetitions + x[:remainder]\n",
    "\n",
    "def find_longest_match(data: bytes, current_position: int, window_size: int, min_pattern_length: int, max_pattern_length: int) -> Optional[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Find the longest repeated match in the given data buffer.\n",
    "\n",
    "    Args:\n",
    "        data (bytes): The data buffer to search for matches.\n",
    "        current_position (int): The current position in the data buffer.\n",
    "        window_size (int): The size of the window to search for patterns.\n",
    "        min_pattern_length (int): The minimum length of a pattern to consider.\n",
    "        max_pattern_length (int): The maximum length of a pattern to consider.\n",
    "\n",
    "    Returns:\n",
    "        Optional[Tuple[int, int]]: A tuple containing the match distance and match length if a match is found,\n",
    "        or None if no match is found.\n",
    "    \"\"\"\n",
    "    # Calculate the end of the buffer where the search should stop\n",
    "    end_of_buffer = min(current_position + min_pattern_length + max_pattern_length, len(data))\n",
    "    # Calculate the starting position of the search window\n",
    "    search_start = max(0, current_position - window_size)\n",
    "    \n",
    "    # Loop through potential match candidate ends in descending order\n",
    "    for match_candidate_end in range(end_of_buffer, current_position + min_pattern_length + 1, -1):\n",
    "        # Extract the candidate sequence for matching\n",
    "        match_candidate = data[current_position:match_candidate_end]\n",
    "        \n",
    "        # Loop through positions in the search window\n",
    "        for search_position in range(search_start, current_position):\n",
    "            # Check if the candidate matches the wrapped slice of data in the search window\n",
    "            if match_candidate == generate_repeated_sequence(data[search_position:current_position], len(match_candidate)):\n",
    "                # If the check is true, we return match distance (offset) and match length\n",
    "                return current_position - search_position, len(match_candidate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Functions\n",
    "\n",
    "Now, we can move ahead and create functions to encode and decode files using the LZSS algorithm. Let's break down the steps each of these functions takes:\n",
    "\n",
    "##### Steps in the `rice_encode_audio_file()` Function\n",
    "1. The function begins by initializing a bitarray to store the compressed data.\n",
    "2. It then iterates through each byte in the input byte array. In each iteration the function checks if an existing byte sequence can be found by the `find_longest_match()` function at the current index. \n",
    "    - If a matching sequence is found, a matching flag bit (`1`) is appended to the output bitarray, followed by the `12 bits` for the match distance (offset) and `4 bits` the match length. A total of `17 bits` is added when a matching sequence is found.\n",
    "   - If no match is found, a not matching flag bit (`0`) is appended to the output bitarray, follwed by the bits of the actual byte itself. A total of `9 bits` is added when a matching sequence is not found.\n",
    "3. After processing all bytes, the bit array is padded to ensure the last byte is complete.\n",
    "4. Finally, the bit array is converted to bytes using tobytes() and returned.\n",
    "\n",
    "##### Steps in the `rice_decode_audio_file()` Function\n",
    "1. The function begins by initializing an empty bit array with the input bytes and creating an empty list called `output_buffer` to store the decoded bytes.\n",
    "2. It then iterates through the initialized bit array until the bit array contains `9 bits` or more (since `9 bits` is the minimum amount used to represent data in the encoding method). During each iteration, a bit is popped from the bit array. If the popped bit is `0`, the following `8 bits` are removed from the bit array, converted to a byte, and appended to the output_buffer. If the popped bit is `1`, the match size and match length are extracted from the next `16 bits`, which are then deleted from the bit array. These extracted values are used to reconstruct the corresponding bytes, which are added to the `output_buffer`.\n",
    "3. The decoded bytes within the `output_buffer` are then returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_MATCH_BIT = True\n",
    "\n",
    "# We only consider patterns between the length of 2 and 15, and just\n",
    "# output any substring of length 1 (9 bits un-encoded is better than a 17-bit\n",
    "# reference for the flag, distance, and length)\n",
    "# Since lengths 0 and 1 are unused, we can encode lengths 2-17(inclusive) in only 4 bits.\n",
    "MIN_PATTERN_LENGTH = 2\n",
    "MAX_PATTERN_LENGTH = 15\n",
    "\n",
    "def lzss_encode(data: bytes, pattern_look_up_window_size: int = 64) -> bytes:\n",
    "    \"\"\"\n",
    "    Encodes the given data using the LZSS algorithm.\n",
    "\n",
    "    Args:\n",
    "        data (bytes): The data to be encoded.\n",
    "\n",
    "    Returns:\n",
    "        bytes: The encoded data.\n",
    "    \"\"\"\n",
    "    output_buffer = bitarray()\n",
    "    \n",
    "    # Initialize progress bar to track encoding progress\n",
    "    with tqdm(total=len(data), desc='LZSS Encoding', leave=True) as progress_bar:\n",
    "        i = 0\n",
    "        \n",
    "        # Process the data byte by byte\n",
    "        while i < len(data):\n",
    "            match = find_longest_match(data, i, pattern_look_up_window_size, MIN_PATTERN_LENGTH, MAX_PATTERN_LENGTH)\n",
    "            # Check if a match is found using the find_longest_match function\n",
    "            if match is not None:\n",
    "                match_distance, match_length = match\n",
    "                \n",
    "                # Append the match flag to the output buffer\n",
    "                output_buffer.append(IS_MATCH_BIT)\n",
    "                # Calculate the high and low parts of the match distance\n",
    "                dist_hi, dist_lo = match_distance >> 4, (match_distance) & 0xF\n",
    "                # Append the match distance and match length to the output buffer\n",
    "                output_buffer.frombytes(bytes([dist_hi, (dist_lo << 4) | (match_length - 2)]))\n",
    "                \n",
    "                # Update the current position in the data and the progress bar\n",
    "                i += match_length\n",
    "                progress_bar.update(match_length)\n",
    "            else:\n",
    "                # If no match is found, append the non-match flag to the output buffer\n",
    "                output_buffer.append(not IS_MATCH_BIT)\n",
    "                # Append the byte from the input data to the output buffer\n",
    "                output_buffer.frombytes(bytes([data[i]]))\n",
    "                \n",
    "                # Update the current position in the data and the progress bar\n",
    "                i += 1\n",
    "                progress_bar.update(1)\n",
    "    \n",
    "    # Pad the output buffer to complete the last byte\n",
    "    output_buffer.fill()\n",
    "    \n",
    "    # Convert the output buffer to bytes and return\n",
    "    return output_buffer.tobytes()\n",
    "\n",
    "def lzss_decode(encoded_bytes: bytes) -> bytes:\n",
    "    \"\"\"\n",
    "    Decodes the given LZSS encoded data.\n",
    "\n",
    "    Args:\n",
    "        encoded_bytes (bytes): The encoded data to be decoded.\n",
    "\n",
    "    Returns:\n",
    "        bytes: The decoded data.\n",
    "    \"\"\"\n",
    "    # Initialize a bitarray to hold the encoded data\n",
    "    data = bitarray()\n",
    "    # Convert the decoded bytes to a bitarray\n",
    "    data.frombytes(encoded_bytes)\n",
    "    # Ensure there's data to decode\n",
    "    assert data, f\"Cannot decode {encoded_bytes}\"\n",
    "\n",
    "    # Initialize a list to store the decoded bytes\n",
    "    output_buffer = []\n",
    "    \n",
    "    # Initialize progress bar to track encoding progress\n",
    "    with tqdm(total=len(data), desc='LZSS Decoding', leave=True) as progress_bar:\n",
    "        # Continue decoding while there are enough bits for a match or non-match flag. Anything less than 9 bits is padding\n",
    "        while len(data) >= 9:\n",
    "            if data.pop(0) != IS_MATCH_BIT:\n",
    "                # If it's a non-match, extract the next 8 bits as a byte\n",
    "                byte = data[:8].tobytes()\n",
    "                del data[:8]\n",
    "                \n",
    "                # Update the progress bar\n",
    "                progress_bar.update(9)\n",
    "                # Append the byte to the output buffer\n",
    "                output_buffer.append(byte)\n",
    "            else:\n",
    "                # If it's a match, extract the next 16 bits as hi and lo bytes\n",
    "                hi, lo = data[:16].tobytes()\n",
    "                del data[:16]\n",
    "                \n",
    "                # Update the progress bar\n",
    "                progress_bar.update(17)\n",
    "                # Calculate the match distance\n",
    "                distance = (hi << 4) | (lo >> 4)\n",
    "                # Calculate the match length\n",
    "                length = (lo & MAX_PATTERN_LENGTH) + MIN_PATTERN_LENGTH\n",
    "                \n",
    "                # Reconstruct the matched substring using history (output_buffer)\n",
    "                for _ in range(length):\n",
    "                    output_buffer.append(output_buffer[-distance])\n",
    "\n",
    "    # Convert the output buffer to bytes and return the decoded data\n",
    "    return b\"\".join(output_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the base functions for LZSS encoding complete, we can create functions for encoding and decoding files using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lzss_encode_file(input_audio_file_path: str, output_audio_file_path: str, pattern_look_up_window_size: int):\n",
    "    \"\"\"\n",
    "    Compresses an audio file using the LZSS algorithm and writes the compressed data to an output file.\n",
    "\n",
    "    Args:\n",
    "        input_audio_file_path (str): The path to the input audio file.\n",
    "        output_audio_file_path (str): The path to the output compressed audio file.\n",
    "        pattern_look_up_window_size (int): The window size for pattern lookup in LZSS encoding(affects speed of the algorithm).\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    audio_buffer = read_file_as_byte_array(input_audio_file_path)\n",
    "\n",
    "    # Using LZSS encoding algorithm to compress audio buffer\n",
    "    compressed_audio_buffer = lzss_encode(audio_buffer, pattern_look_up_window_size)\n",
    "\n",
    "    # Writing encoded audio samples to output file\n",
    "    with open(output_audio_file_path, 'wb+') as output_file:\n",
    "        output_file.write(compressed_audio_buffer)\n",
    "\n",
    "def lzss_decode_file(input_audio_file_path: str, output_audio_file_path: str):\n",
    "    \"\"\"\n",
    "    Decompresses a previously LZSS compressed audio file and writes the decompressed data to an output file.\n",
    "\n",
    "    Args:\n",
    "        input_audio_file_path (str): The path to the input compressed audio file.\n",
    "        output_audio_file_path (str): The path to the output decompressed audio file.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    compressed_audio_buffer = read_file_as_byte_array(input_audio_file_path)\n",
    "\n",
    "    # Using LZSS decoding algorithm to decompress buffer\n",
    "    audio_buffer = lzss_decode(compressed_audio_buffer)\n",
    "\n",
    "    # Writing encoded audio samples to output file\n",
    "    with open(output_audio_file_path, 'wb+') as output_file:\n",
    "        output_file.write(audio_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing\n",
    "\n",
    "Now that we have the functions ready, we can test them out and compare the results. When it comes to the LZSS algorithm, making the pattern detection window larger can usually make the compression better. However, we have to keep in mind that this will also slow down the encoding process because each byte needs to be compared with `n` previous bytes(where `n` is the window_size). For our tests, we'll use a relatively small window size of `64`.\n",
    "\n",
    "The code snippet below will encode the `./files/Sound1.wav` file, decode the encoded file, and then compare the original file with the final decoded file to verify the correctness of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11a94340e0a4d78b5c8a6a8fddb3367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='LZSS Encoding', max=1002088.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9234b9830a41b7a249693904e6c019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='LZSS Decoding', max=7666392.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The encoding and decoding functions work!\n"
     ]
    }
   ],
   "source": [
    "lzss_encode_file('./Exercise_2_Files/Sound1.wav', './Exercise_2_Output/Sound1_Enc_Win_64.lzss', 64)\n",
    "lzss_decode_file('./Exercise_2_Output/Sound1_Enc_Win_64.lzss', './Exercise_2_Output/Sound1_Enc_Win_64_Dec_lzss.wav')\n",
    "\n",
    "# Comparing original file with the decoded file\n",
    "if compare_files('./Exercise_2_Files/Sound1.wav', './Exercise_2_Output/Sound1_Enc_Win_64_Dec_lzss.wav'):\n",
    "    print('The encoding and decoding functions work!')\n",
    "else:\n",
    "    print('Something is wrong with the encoding and decoding functions!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output of the above cell, we can see the LZSS encoding and decoding functions work as expected.\n",
    "\n",
    "#### Compression Result\n",
    "\n",
    "With the working encoding and decoding functions working, we can now construct a table showing the compression results\n",
    "\n",
    "To do that we will encode the `./files/Sound1.wav` and `./files/Sound2.wav` files using both `k` values of `2` and `4` and compare file sizes to create the table using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747122a16f9e4d6e8bbc577d932f8169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='LZSS Encoding', max=1002088.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2089c86c69fd49bd8f191323efb33f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='LZSS Encoding', max=1002088.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a2555b3e18447c9cd2d931746ba053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='LZSS Encoding', max=1008044.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2113a078bdf6413588329df46b02857c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='LZSS Encoding', max=1008044.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>window_size</th>\n",
       "      <th>original_size</th>\n",
       "      <th>compressed_size</th>\n",
       "      <th>compression_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sound1.wav</td>\n",
       "      <td>64</td>\n",
       "      <td>1002088</td>\n",
       "      <td>958299</td>\n",
       "      <td>95.630224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sound1.wav</td>\n",
       "      <td>128</td>\n",
       "      <td>1002088</td>\n",
       "      <td>932662</td>\n",
       "      <td>93.071866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sound2.wav</td>\n",
       "      <td>64</td>\n",
       "      <td>1008044</td>\n",
       "      <td>1134040</td>\n",
       "      <td>112.499058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sound2.wav</td>\n",
       "      <td>128</td>\n",
       "      <td>1008044</td>\n",
       "      <td>1134038</td>\n",
       "      <td>112.498859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name  window_size  original_size  compressed_size  \\\n",
       "0  Sound1.wav           64        1002088           958299   \n",
       "1  Sound1.wav          128        1002088           932662   \n",
       "2  Sound2.wav           64        1008044          1134040   \n",
       "3  Sound2.wav          128        1008044          1134038   \n",
       "\n",
       "   compression_percentage  \n",
       "0               95.630224  \n",
       "1               93.071866  \n",
       "2              112.499058  \n",
       "3              112.498859  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "audio_file_encoding_configs = [\n",
    "    {\n",
    "        'file_name': 'Sound1.wav',\n",
    "        'input_file_path': './Exercise_2_Files/Sound1.wav',\n",
    "        'output_file_path': './Exercise_2_Output/Sound1_Enc_Win_64.lzss',\n",
    "        'window_size': 64\n",
    "    },\n",
    "    {\n",
    "        'file_name': 'Sound1.wav',\n",
    "        'input_file_path': './Exercise_2_Files/Sound1.wav',\n",
    "        'output_file_path': './Exercise_2_Output/Sound1_Enc_Win_128.lzss',\n",
    "        'window_size': 128\n",
    "    },\n",
    "    {\n",
    "        'file_name': 'Sound2.wav',\n",
    "        'input_file_path': './Exercise_2_Files/Sound2.wav',\n",
    "        'output_file_path': './Exercise_2_Output/Sound2_Enc_Win_64.lzss',\n",
    "        'window_size': 64\n",
    "    },\n",
    "    {\n",
    "        'file_name': 'Sound2.wav',\n",
    "        'input_file_path': './Exercise_2_Files/Sound2.wav',\n",
    "        'output_file_path': './Exercise_2_Output/Sound2_Enc_Win_128.lzss',\n",
    "        'window_size': 128\n",
    "    },\n",
    "]\n",
    "\n",
    "file_size_dataframe = pd.DataFrame()\n",
    "\n",
    "for config in audio_file_encoding_configs:\n",
    "    file_name = config['file_name']\n",
    "    input_file_path = config['input_file_path']\n",
    "    output_file_path = config['output_file_path']\n",
    "    window_size = config['window_size']\n",
    "    \n",
    "    lzss_encode_file(input_file_path, output_file_path, window_size)\n",
    "    \n",
    "    original_size, compressed_size = os.path.getsize(config['input_file_path']), os.path.getsize(config['output_file_path'])\n",
    "    compression_percentage = (compressed_size / original_size) * 100\n",
    "    \n",
    "    new_row = {\n",
    "        'file_name': file_name, \n",
    "        'window_size': window_size,\n",
    "        'original_size': original_size, \n",
    "        'compressed_size': compressed_size,\n",
    "        'compression_percentage': compression_percentage\n",
    "    }\n",
    "    file_size_dataframe = pd.concat([file_size_dataframe, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "file_size_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
